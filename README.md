# Toxic-Comment-Detection-with-DistilBERT-Attention-Based-Explainability
Developed a multi-label toxic comment detection system using DistilBERT, fine-tuned on over 160,000 online comments to classify six categories of toxicity with F1 scores exceeding 0.83. Optimized performance through focal loss, early stopping, and per-label threshold tuning based on validation F1 maximization. Deployed model in an interactive Gradio web application featuring instant predictions and attention-based interpretability, allowing users to see which words influenced model’s decisions. Enables real-time content moderation, promoting safer online interactions and offering scalable, interpretable tool for managing user-generated content.

## Disclaimer  
This repository is a **class project** created for coursework at the University of South Florida.  

- It is **not a polished, complete, or fully working application** — in fact, parts of it may be broken, incomplete or flat out incorrect.
- This repo is not as organized as I would like it to be.
- It is **not intended for plug-and-play use** or production.  
- The main purpose of this repo is to **showcase academic work and skills** for learning and resume/visibility purposes.  

Please treat this project as a proof-of-concept and learning exercise only.
